# Vlastní vektor (Eigenvector)

## Summary
Any such non-zero vector $x$ is called an eigenvector corresponding to the eigenvalue $\lambda$.

## Detailed Explanation
An **eigenvector** is a special non-zero vector that, when a linear transformation is applied to it, changes only by a scalar factor. This scalar factor is known as the **eigenvalue**. Specifically, for a linear transformation $f: L \rightarrow L$ (or its matrix representation $A$), if $f(x) = \lambda \cdot x$ (or $Ax = \lambda x$) for some scalar $\lambda$, then $x$ is an eigenvector corresponding to the eigenvalue $\lambda$.

Crucially, an eigenvector must be a non-zero vector. If $x$ were the zero vector, the equation $f(0) = \lambda \cdot 0$ would always hold true for any $\lambda$, which would not provide meaningful information about the transformation. Eigenvectors define the directions in which a linear transformation acts as a simple scaling. Each eigenvector corresponds to a specific eigenvalue, and vice-versa.

## Importance/Relevance
With an overall importance score of 1.0, eigenvectors are fundamental and critical in linear algebra. Together with eigenvalues, they form the bedrock for understanding many properties of linear transformations and matrices. They are essential for processes like diagonalization, solving differential equations, understanding dynamic systems, and are widely applied in fields such as quantum mechanics, structural engineering, and data analysis.

## Connections
This concept appears in the following lectures:
*   "Vlastní hodnoty a vlastní vektory" (lecture-eigenvalues-eigenvectors-08a-2024)

There are no known aliases for this term.

## Category
Fundamental Concept